# CEIA-ViT 
![vision_transformers](https://github.com/user-attachments/assets/4eb2ee5d-578e-4c22-998e-b9acc3ceae05)


## Bibliografía

Rothman, D. (2024) "Transformers for Natural Language Processing and Computer Vision: Explore Generative AI and Large Language Models with Hugging Face, ChatGPT, GPT-4V, and DALL-E." Packt Publishing; 3rd edition.

Dosovitskiy, A., et al. (2020) "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale." arXiv preprint arXiv:2010.11929.
[Link](https://arxiv.org/abs/2010.11929)

Vaswani, A., et al. (2017) "Attention is All You Need." Advances in Neural Information Processing Systems (NeurIPS).
[Link](https://arxiv.org/abs/1706.03762)

Haoran Z., et al. (2023) "Understanding Why ViT Trains Badly on Small Datasets: An Intuitive Perspective"
[Link](https://arxiv.org/pdf/2302.03751)

Touvron, H., et al. (2021) "Training data-efficient image transformers & distillation through attention." International Conference on Machine Learning (ICML).
[Link](https://arxiv.org/abs/2012.12877)

Carion, N., et al. (2020) "End-to-End Object Detection with Transformers." European Conference on Computer Vision (ECCV).
[Link](https://arxiv.org/abs/2005.12872)

Yuan, L., et al. (2021) "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet." IEEE International Conference on Computer Vision (ICCV).
[Link](https://arxiv.org/abs/2101.11986)

---

Wu, B., et al. (2021) "CvT: Introducing Convolutions to Vision Transformers." International Conference on Computer Vision (ICCV).
[Link](https://arxiv.org/abs/2103.15808)

"Transformers and Visual Transformers, Part of the book series: Neuromethods" ((NM,volume 197)) 
[Link](https://link.springer.com/protocol/10.1007/978-1-0716-3195-9_6#keywords)

Ze Liu, Yutong Lin et.al (2021), "Swin Transformer: Hierarchical Vision Transformer Using Shifted Windows", ICCV  
[Link-paper](https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper.html),  [Link-huggingface](https://huggingface.co/docs/transformers/model_doc/swin)

Sachin Mehta y Mohammad Rastegari, "MOBILEVIT: Light-Weight, general-purpose, and mobile-friendly vision transformer” 
[Link-paper](https://arxiv.org/abs/2110.02178), [Link-huggingface](https://huggingface.co/docs/transformers/model_doc/mobilevit)

Wenhai Wang et.al. (2021), "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions" 
[Link-paper](https://arxiv.org/abs/2102.12122), [Link-huggingface](https://huggingface.co/docs/transformers/v4.45.2/en/model_doc/pvt#transformers.PvtForImageClassification)




### Docentes a cargo: 

Esp. Abraham Rodriguez (abraham.rodz17@gmail.com); Mg. Oksana Bokhonok (bokhonokok@gmail.com)


